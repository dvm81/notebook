"""
Test script to verify bert_score uses local roberta-large model.

This script:
1. Sets environment variables to force offline mode
2. Points to local roberta-large/ directory
3. Tests bert_score with sample summaries
4. Verifies no downloads occur
"""

import os
from pathlib import Path

# Force offline mode - prevent any downloads
os.environ['HF_HUB_OFFLINE'] = '1'
os.environ['TRANSFORMERS_OFFLINE'] = '1'

# Point to local model directory
local_model_dir = Path("roberta-large").absolute()
os.environ['TRANSFORMERS_CACHE'] = str(local_model_dir.parent)
os.environ['HF_HOME'] = str(local_model_dir.parent)

print("="*80)
print("Testing bert_score with Local RoBERTa Model")
print("="*80)
print(f"\nüìÅ Local model directory: {local_model_dir}")
print(f"   Exists: {local_model_dir.exists()}")
print(f"   Has config: {(local_model_dir / 'config.json').exists()}")
print(f"\nüîí Offline mode: HF_HUB_OFFLINE={os.environ.get('HF_HUB_OFFLINE')}")
print(f"   TRANSFORMERS_OFFLINE={os.environ.get('TRANSFORMERS_OFFLINE')}")
print()

# Sample text from your evaluation
reference = """NextEra reported Q4 2024 adjusted EPS of $0.98, FY2024 EPS $3.35 (+10% YoY). Record renewable backlog of 24 GW (up from 18 GW YoY), representing $35B capex through 2027: solar 14 GW, wind 7 GW, storage 3 GW."""

hypothesis = """NextEra Energy delivered Q4 2024 adjusted EPS of $0.98, with full-year EPS of $3.35 (+10% YoY), meeting guidance. Renewable expansion accelerating with record 24 GW backlog (vs 18 GW prior year), translating to $35B capital deployment through 2027."""

try:
    import bert_score

    print("-"*80)
    print("üîÑ Calculating BERTScore...")
    print("-"*80)

    # Try to use local model by specifying path
    # bert_score library expects model_type as HuggingFace identifier or path
    P, R, F1 = bert_score.score(
        [hypothesis],
        [reference],
        model_type=str(local_model_dir),  # Try local path
        lang='en',
        rescale_with_baseline=True,
        verbose=True  # Show what's happening
    )

    print("\n" + "="*80)
    print("‚úì SUCCESS: BERTScore calculated with local model!")
    print("="*80)
    print(f"\nüìä Results:")
    print(f"   Precision: {P.item():.4f}")
    print(f"   Recall:    {R.item():.4f}")
    print(f"   F1:        {F1.item():.4f}")

    print(f"\nüí° Interpretation:")
    if F1.item() > 0.9:
        interpretation = "excellent semantic similarity"
    elif F1.item() > 0.85:
        interpretation = "very good semantic similarity"
    elif F1.item() > 0.7:
        interpretation = "good semantic similarity"
    elif F1.item() > 0.5:
        interpretation = "fair semantic similarity"
    else:
        interpretation = "poor semantic similarity"

    print(f"   F1 = {F1.item():.4f} indicates {interpretation}")

    print("\n" + "="*80)
    print("‚úì Test passed! bert_score is working with local model.")
    print("  No downloads occurred (offline mode was enforced)")
    print("\nüìù Key Findings:")
    print("  ‚Ä¢ bert_score uses local roberta-large/ via environment variables")
    print("  ‚Ä¢ Use model_type='roberta-large' (identifier), not path")
    print("  ‚Ä¢ Realistic scores: F1 ~0.6 (vs manual calculation ~0.97)")
    print("  ‚Ä¢ Environment vars: HF_HUB_OFFLINE=1, TRANSFORMERS_CACHE set")
    print("="*80)

except Exception as e:
    print("\n" + "="*80)
    print("‚úó FAILED: Could not use local model")
    print("="*80)
    print(f"\nError: {e}")
    print("\nTrying alternative approach with 'roberta-large' identifier...")
    print("(This may download if local cache not found)")

    try:
        # Fallback: try with model identifier
        P, R, F1 = bert_score.score(
            [hypothesis],
            [reference],
            model_type='roberta-large',  # HuggingFace identifier
            lang='en',
            rescale_with_baseline=True,
            verbose=True
        )

        print(f"\nüìä Results with fallback:")
        print(f"   F1: {F1.item():.4f}")
        print("\n‚ö† Note: Check if download occurred above")

    except Exception as e2:
        print(f"\n‚úó Fallback also failed: {e2}")
        import traceback
        traceback.print_exc()
